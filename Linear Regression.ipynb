{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade6c4bf",
   "metadata": {},
   "source": [
    "# Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b996f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"\n",
    "    OLS Linear Regression.\n",
    "\n",
    "    LinearRegression fits a linear model with k regressors, with fitted coefficients \n",
    "    b = (b1, ..., bk) to minimize the residual sum of squares between the observed \n",
    "    target variable in the dataset, and the target predicted by the linear approximation.\n",
    "    \n",
    "    Needed packages:\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fit_intercept : bool, default=True\n",
    "        Whether to calculate the intercept for this model. If set to False, \n",
    "        no intercept will be used in calculations (e.g. use if data is centered).\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    coefficients : array of shape k+1: #features/regressors + 1\n",
    "        Estimated coefficients for the linear regression problem.\n",
    "        This includes the intercept, as first value in the array.\n",
    "        \n",
    "    intercept : array of shape 1\n",
    "    Independent term/constant in the linear model. Set to 0.0 if fit_intercept = False.\n",
    "    \n",
    "    residuals : array of shape N\n",
    "        Estimated residuals, defined as the difference between the predicted,\n",
    "        and the true y-value\n",
    "        \n",
    "    se_coefficients : array of shape k+1\n",
    "        Estimated standard errors of estimated regression coefficients.\n",
    "    \n",
    "    t_values : array of shape k+1\n",
    "        Estimated t-values of estimated regression coefficients, for H0: b=0.\n",
    "    \n",
    "    p_values : array of shape k+1\n",
    "        Estimated p-values of estimated regression coefficients, for H0: b=0.\n",
    "        \n",
    "    residualmakermatrix : array of shape (N, N)\n",
    "        Matrix M is called the residual maker matrix since it makes residuals out of y.\n",
    "        \n",
    "    hatmatrix : array of shape (N, N)\n",
    "        Matrix H is called the hat matrix since it makes the fitted y out of y.\n",
    "\n",
    "    n_features : int\n",
    "        Number of features seen during method `fit`, excluding intercept.\n",
    "        \n",
    "\n",
    "        \n",
    "    Methods\n",
    "    ----------\n",
    "    fit(X, y): \n",
    "        Fit linear model, and create attributes\n",
    "    \n",
    "    predict(X): \n",
    "        Predict target variable, using the fitted parameters of this estimator.\n",
    "    \n",
    "    R_squared(X,y): \n",
    "        Return the coefficient of determination of the prediction.\n",
    "    \n",
    "    adjusted_R_squared(X,y): \n",
    "        Return the adjusted coefficient of determination of the prediction.\n",
    "    \n",
    "    summary(decimals): \n",
    "        Print summary of regression output after fit.\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "    >>> y = np.array([[0], [4], [0], [6]])\n",
    "    >>> regfit = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "    >>> regfit.summary()\n",
    "    Regression output:\n",
    "               Coefficient  S.E.       t-value    p-value   \n",
    "    Intercept  -1.5         1.658      -0.905     0.532     \n",
    "    X1         -4.0         1.414      -2.828     0.216     \n",
    "    X2         5.0          1.0        5.0        0.126     \n",
    "\n",
    "    Residuals:\n",
    "    [-0.5  0.5  0.5 -0.5]\n",
    "\n",
    "    R-squared: 0.963               \t Adjusted R-squared: 0.889\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        fit_intercept=True,\n",
    "    ):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit linear regression model, simple OLS.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array of shape Nxk (Training data)\n",
    "        y : array of shape N (Target values)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted Estimator.\n",
    "        \"\"\"\n",
    "        # Define n_features\n",
    "        self.n_features = len(X[0])\n",
    "        \n",
    "        # Define coefficients\n",
    "        if self.fit_intercept == True:\n",
    "            X = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "            self.coefficients = (np.linalg.inv(X.T@X)@np.transpose(X)@y).T\n",
    "            self.intercept = self.coefficients[:,0]\n",
    "        else:\n",
    "            self.coefficients = (np.linalg.inv(X.T@X)@np.transpose(X)@y).T\n",
    "            self.intercept = 0.0\n",
    "            \n",
    "        # Define residuals\n",
    "        y_predicted = self.coefficients @ X.T\n",
    "        self.residuals = y_predicted.T - y\n",
    "        \n",
    "        # Define standard error of coefficients\n",
    "        self.var_hat = np.sum(self.residuals**2)\n",
    "        self.se_coefficients = self.var_hat * np.sqrt(np.diagonal(np.linalg.inv(X.T@X)))\n",
    "        \n",
    "        # Define t- and p-values for Null hypothesis H0: b=0\n",
    "        self.t_values = self.coefficients / self.se_coefficients\n",
    "        if self.fit_intercept == True:\n",
    "            df = len(X) - len(X[0])\n",
    "        else:\n",
    "            df = len(X) - len(X[0]) - 1\n",
    "        self.p_values = 2*(1 - stats.t.cdf(abs(self.t_values), df))\n",
    "\n",
    "        # Define H,M matrices\n",
    "        self.residualmakermatrix = np.identity(len(X)) - X @ np.linalg.inv(X.T@X) @ X.T\n",
    "        self.hatmatrix = X @ np.linalg.inv(X.T@X) @ X.T\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the fitted parameters of this Linear Regression estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array of shape M, k-1\n",
    "            M values for k-1 regressors test data. Don't add 1 for the intercept.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : array of shape M\n",
    "            Returns predicted value.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'coefficients') == False:\n",
    "                raise ValueError(\n",
    "                     \" This LinearRegression instance is not fitted yet.\" \\\n",
    "                     \" Call 'fit' method with appropriate X and y before using this predict function.\"\n",
    "                 )\n",
    "                \n",
    "        if self.fit_intercept == True:\n",
    "            X = np.vstack([np.ones(len(X)), X.T]).T\n",
    "        \n",
    "        y_predicted = self.coefficients @ X.T\n",
    "\n",
    "        return y_predicted.T\n",
    "    \n",
    "    def R_squared(self, X, y):\n",
    "        \"\"\"Return the coefficient of determination of the prediction.\n",
    "\n",
    "        The coefficient of determination R^2 is defined as the residual\n",
    "        sum of squares divided by the total sum of squares. The best possible R^2\n",
    "        score is 1.0, explaining all variance in the data. The R^2 score can be negative\n",
    "        when no constant is included, or the model is made arbitrarily bad. A model \n",
    "        always predicting the mean of y, the expected value of y, disregarding the input \n",
    "        features, gets a R^2 score of 0.0.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array of shape Nxk\n",
    "        y : array of shape N\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        R_squared : float\n",
    "            R^2 score of predicted X wrt. true y\n",
    "        \"\"\"\n",
    "        \n",
    "        if hasattr(self, 'coefficients') == False:\n",
    "                raise ValueError(\n",
    "                     \" This LinearRegression instance is not fitted yet.\" \\\n",
    "                     \" Call 'fit' method with appropriate X and y before using this score function.\"\n",
    "                 )\n",
    "        \n",
    "        SSR = sum((y - self.predict(X))**2)\n",
    "        SST = sum((y - y.mean())**2)\n",
    "        R_squared = (1 - SSR/SST)[0]\n",
    "        \n",
    "        return R_squared\n",
    "    \n",
    "    def adjusted_R_squared(self, X, y):\n",
    "        \"\"\"Return the adjusted coefficient of determination of the prediction.\n",
    "\n",
    "        The adjusted coefficient of determination R^2 is defined as the residual\n",
    "        sum of squares divided by N-k, divided by the total sum of squares, divided by N-1. \n",
    "        This allows penalty for #regressors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array of shape Nxk\n",
    "        y : array of shape N\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        adjusted_R_squared : float\n",
    "            Adjusted R^2 score of predicted X wrt. true y\n",
    "        \"\"\"\n",
    "        \n",
    "        if hasattr(self, 'coefficients') == False:\n",
    "                raise ValueError(\n",
    "                     \" This LinearRegression instance is not fitted yet.\" \\\n",
    "                     \" Call 'fit' method with appropriate X and y before using this score function.\"\n",
    "                 )\n",
    "        \n",
    "        N = len(X)\n",
    "        k = len(X[0])\n",
    "        \n",
    "        R2 = self.R_squared(X,y)\n",
    "        adjusted_R_squared = 1 - ((N-1)/(N-k-1))* (1 - R2)\n",
    "        \n",
    "        return adjusted_R_squared\n",
    "    \n",
    "    \n",
    "    def summary(self, decimals=3):\n",
    "        \"\"\"Returns the table of the regression output.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        decimals : int, default=3\n",
    "            Number of decimals to round to in the table.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        regression_table : table\n",
    "            Table of the regression output.\n",
    "        \"\"\"\n",
    "        \n",
    "        if hasattr(self, 'coefficients') == False:\n",
    "                raise ValueError(\n",
    "                     \" This LinearRegression instance is not fitted yet.\" \\\n",
    "                     \" Call 'fit' method with appropriate X and y before using this predict function.\"\n",
    "                 )\n",
    "\n",
    "        print('Regression output:')\n",
    "        table = np.concatenate((regfit.coefficients, \n",
    "                        regfit.se_coefficients.reshape(1,len(regfit.coefficients[0])),\n",
    "                        regfit.t_values, \n",
    "                        regfit.p_values), axis=0).T\n",
    "\n",
    "        regression_dict = dict()\n",
    "        for num in range(len(regfit.coefficients[0])):\n",
    "            if num == 0:\n",
    "                if self.fit_intercept == True:\n",
    "                    regression_dict['Intercept'] = table[num]\n",
    "                else:\n",
    "                    regression_dict['X1'] = table[num]\n",
    "            else:\n",
    "                if self.fit_intercept == True:\n",
    "                    string = f\"X{num}\"\n",
    "                    regression_dict[string] = table[num]\n",
    "                else:\n",
    "                    string = f\"X{num+1}\"\n",
    "                    regression_dict[string] = table[num]\n",
    "        \n",
    "        if decimals < 4:\n",
    "            L = 10\n",
    "        else:\n",
    "            L = decimals + 7\n",
    "                \n",
    "        print(\"{:<{L}} {:<{L2}} {:<{L}} {:<{L}} {:<{L}}\".format('', 'Coefficient', 'S.E.', 't-value', 'p-value', \n",
    "                                                                L=L, L2=L+2))\n",
    "        for k, v in regression_dict.items():\n",
    "            estim, se, tval, pval = v\n",
    "            print(\"{:<{L}} {:<{L2}} {:<{L}} {:<{L}} {:<{L}}\".format(k, \n",
    "                                                              round(estim, decimals), \n",
    "                                                              round(se, decimals), \n",
    "                                                              round(tval, decimals),\n",
    "                                                              round(pval,decimals), L=L, L2=L+2))\n",
    "\n",
    "        print('\\nResiduals:')\n",
    "        print(regfit.residuals.T[0])\n",
    "\n",
    "        print(f'\\nR-squared: {round(regfit.R_squared(X,y), decimals)} \\\n",
    "              \\t Adjusted R-squared: {round(regfit.adjusted_R_squared(X,y), decimals)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd9f7b",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071d970b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5, -4. ,  5. ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.array([[0], [4], [0], [6]])\n",
    "\n",
    "regfit = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "regfit.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a1c036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73aa381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [-0.5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b05411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6583124 , 1.41421356, 1.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.se_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3a8223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90453403, -2.82842712,  5.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.t_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12210bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53188428, 0.2163469 , 0.12566592]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef8ac53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25, -0.25, -0.25,  0.25],\n",
       "       [-0.25,  0.25,  0.25, -0.25],\n",
       "       [-0.25,  0.25,  0.25, -0.25],\n",
       "       [ 0.25, -0.25, -0.25,  0.25]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regfit.residuals == regfit.residualmakermatrix @ y\n",
    "regfit.residualmakermatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac2196d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75,  0.25,  0.25, -0.25],\n",
       "       [ 0.25,  0.75, -0.25,  0.25],\n",
       "       [ 0.25, -0.25,  0.75,  0.25],\n",
       "       [-0.25,  0.25,  0.25,  0.75]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regfit.predict(X) == regfit.hatmatrix @ y\n",
    "regfit.hatmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5711b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76499e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5],\n",
       "       [ 4.5],\n",
       "       [ 0.5],\n",
       "       [ 5.5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82392b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962962962962963"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.R_squared(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3b441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888891"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regfit.adjusted_R_squared(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35c51446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression output:\n",
      "           Coefficient  S.E.       t-value    p-value   \n",
      "Intercept  -1.5         1.658      -0.905     0.532     \n",
      "X1         -4.0         1.414      -2.828     0.216     \n",
      "X2         5.0          1.0        5.0        0.126     \n",
      "\n",
      "Residuals:\n",
      "[-0.5  0.5  0.5 -0.5]\n",
      "\n",
      "R-squared: 0.963               \t Adjusted R-squared: 0.889\n"
     ]
    }
   ],
   "source": [
    "regfit.summary(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
