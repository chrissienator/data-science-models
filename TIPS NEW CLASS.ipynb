{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635528c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tips for new definition class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b737f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See other package by:\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import inspect\n",
    "\n",
    "LinearRegression??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a392701b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sklearn.linear_model._base.LinearRegression,\n",
       " sklearn.base.MultiOutputMixin,\n",
       " sklearn.base.RegressorMixin,\n",
       " sklearn.linear_model._base.LinearModel,\n",
       " sklearn.base.BaseEstimator,\n",
       " object]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30247ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"Base classes for all estimators.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "# Author: Gael Varoquaux <gael.varoquaux@normalesup.org>\n",
      "\n",
      "# License: BSD 3 clause\n",
      "\n",
      "\n",
      "\n",
      "import copy\n",
      "\n",
      "import warnings\n",
      "\n",
      "from collections import defaultdict\n",
      "\n",
      "import platform\n",
      "\n",
      "import inspect\n",
      "\n",
      "import re\n",
      "\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "\n",
      "from . import __version__\n",
      "\n",
      "from ._config import get_config\n",
      "\n",
      "from .utils import _IS_32BIT\n",
      "\n",
      "from .utils._tags import (\n",
      "\n",
      "    _DEFAULT_TAGS,\n",
      "\n",
      "    _safe_tags,\n",
      "\n",
      ")\n",
      "\n",
      "from .utils.validation import check_X_y\n",
      "\n",
      "from .utils.validation import check_array\n",
      "\n",
      "from .utils.validation import _check_y\n",
      "\n",
      "from .utils.validation import _num_features\n",
      "\n",
      "from .utils.validation import _check_feature_names_in\n",
      "\n",
      "from .utils._estimator_html_repr import estimator_html_repr\n",
      "\n",
      "from .utils.validation import _get_feature_names\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def clone(estimator, *, safe=True):\n",
      "\n",
      "    \"\"\"Construct a new unfitted estimator with the same parameters.\n",
      "\n",
      "\n",
      "\n",
      "    Clone does a deep copy of the model in an estimator\n",
      "\n",
      "    without actually copying attached data. It returns a new estimator\n",
      "\n",
      "    with the same parameters that has not been fitted on any data.\n",
      "\n",
      "\n",
      "\n",
      "    Parameters\n",
      "\n",
      "    ----------\n",
      "\n",
      "    estimator : {list, tuple, set} of estimator instance or a single \\\n",
      "\n",
      "            estimator instance\n",
      "\n",
      "        The estimator or group of estimators to be cloned.\n",
      "\n",
      "    safe : bool, default=True\n",
      "\n",
      "        If safe is False, clone will fall back to a deep copy on objects\n",
      "\n",
      "        that are not estimators.\n",
      "\n",
      "\n",
      "\n",
      "    Returns\n",
      "\n",
      "    -------\n",
      "\n",
      "    estimator : object\n",
      "\n",
      "        The deep copy of the input, an estimator if input is an estimator.\n",
      "\n",
      "\n",
      "\n",
      "    Notes\n",
      "\n",
      "    -----\n",
      "\n",
      "    If the estimator's `random_state` parameter is an integer (or if the\n",
      "\n",
      "    estimator doesn't have a `random_state` parameter), an *exact clone* is\n",
      "\n",
      "    returned: the clone and the original estimator will give the exact same\n",
      "\n",
      "    results. Otherwise, *statistical clone* is returned: the clone might\n",
      "\n",
      "    return different results from the original estimator. More details can be\n",
      "\n",
      "    found in :ref:`randomness`.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    estimator_type = type(estimator)\n",
      "\n",
      "    # XXX: not handling dictionaries\n",
      "\n",
      "    if estimator_type in (list, tuple, set, frozenset):\n",
      "\n",
      "        return estimator_type([clone(e, safe=safe) for e in estimator])\n",
      "\n",
      "    elif not hasattr(estimator, \"get_params\") or isinstance(estimator, type):\n",
      "\n",
      "        if not safe:\n",
      "\n",
      "            return copy.deepcopy(estimator)\n",
      "\n",
      "        else:\n",
      "\n",
      "            if isinstance(estimator, type):\n",
      "\n",
      "                raise TypeError(\n",
      "\n",
      "                    \"Cannot clone object. \"\n",
      "\n",
      "                    + \"You should provide an instance of \"\n",
      "\n",
      "                    + \"scikit-learn estimator instead of a class.\"\n",
      "\n",
      "                )\n",
      "\n",
      "            else:\n",
      "\n",
      "                raise TypeError(\n",
      "\n",
      "                    \"Cannot clone object '%s' (type %s): \"\n",
      "\n",
      "                    \"it does not seem to be a scikit-learn \"\n",
      "\n",
      "                    \"estimator as it does not implement a \"\n",
      "\n",
      "                    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
      "\n",
      "                )\n",
      "\n",
      "\n",
      "\n",
      "    klass = estimator.__class__\n",
      "\n",
      "    new_object_params = estimator.get_params(deep=False)\n",
      "\n",
      "    for name, param in new_object_params.items():\n",
      "\n",
      "        new_object_params[name] = clone(param, safe=False)\n",
      "\n",
      "    new_object = klass(**new_object_params)\n",
      "\n",
      "    params_set = new_object.get_params(deep=False)\n",
      "\n",
      "\n",
      "\n",
      "    # quick sanity check of the parameters of the clone\n",
      "\n",
      "    for name in new_object_params:\n",
      "\n",
      "        param1 = new_object_params[name]\n",
      "\n",
      "        param2 = params_set[name]\n",
      "\n",
      "        if param1 is not param2:\n",
      "\n",
      "            raise RuntimeError(\n",
      "\n",
      "                \"Cannot clone object %s, as the constructor \"\n",
      "\n",
      "                \"either does not set or modifies parameter %s\" % (estimator, name)\n",
      "\n",
      "            )\n",
      "\n",
      "    return new_object\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def _pprint(params, offset=0, printer=repr):\n",
      "\n",
      "    \"\"\"Pretty print the dictionary 'params'\n",
      "\n",
      "\n",
      "\n",
      "    Parameters\n",
      "\n",
      "    ----------\n",
      "\n",
      "    params : dict\n",
      "\n",
      "        The dictionary to pretty print\n",
      "\n",
      "\n",
      "\n",
      "    offset : int, default=0\n",
      "\n",
      "        The offset in characters to add at the begin of each line.\n",
      "\n",
      "\n",
      "\n",
      "    printer : callable, default=repr\n",
      "\n",
      "        The function to convert entries to strings, typically\n",
      "\n",
      "        the builtin str or repr\n",
      "\n",
      "\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # Do a multi-line justified repr:\n",
      "\n",
      "    options = np.get_printoptions()\n",
      "\n",
      "    np.set_printoptions(precision=5, threshold=64, edgeitems=2)\n",
      "\n",
      "    params_list = list()\n",
      "\n",
      "    this_line_length = offset\n",
      "\n",
      "    line_sep = \",\\n\" + (1 + offset // 2) * \" \"\n",
      "\n",
      "    for i, (k, v) in enumerate(sorted(params.items())):\n",
      "\n",
      "        if type(v) is float:\n",
      "\n",
      "            # use str for representing floating point numbers\n",
      "\n",
      "            # this way we get consistent representation across\n",
      "\n",
      "            # architectures and versions.\n",
      "\n",
      "            this_repr = \"%s=%s\" % (k, str(v))\n",
      "\n",
      "        else:\n",
      "\n",
      "            # use repr of the rest\n",
      "\n",
      "            this_repr = \"%s=%s\" % (k, printer(v))\n",
      "\n",
      "        if len(this_repr) > 500:\n",
      "\n",
      "            this_repr = this_repr[:300] + \"...\" + this_repr[-100:]\n",
      "\n",
      "        if i > 0:\n",
      "\n",
      "            if this_line_length + len(this_repr) >= 75 or \"\\n\" in this_repr:\n",
      "\n",
      "                params_list.append(line_sep)\n",
      "\n",
      "                this_line_length = len(line_sep)\n",
      "\n",
      "            else:\n",
      "\n",
      "                params_list.append(\", \")\n",
      "\n",
      "                this_line_length += 2\n",
      "\n",
      "        params_list.append(this_repr)\n",
      "\n",
      "        this_line_length += len(this_repr)\n",
      "\n",
      "\n",
      "\n",
      "    np.set_printoptions(**options)\n",
      "\n",
      "    lines = \"\".join(params_list)\n",
      "\n",
      "    # Strip trailing space to avoid nightmare in doctests\n",
      "\n",
      "    lines = \"\\n\".join(l.rstrip(\" \") for l in lines.split(\"\\n\"))\n",
      "\n",
      "    return lines\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class BaseEstimator:\n",
      "\n",
      "    \"\"\"Base class for all estimators in scikit-learn.\n",
      "\n",
      "\n",
      "\n",
      "    Notes\n",
      "\n",
      "    -----\n",
      "\n",
      "    All estimators should specify all the parameters that can be set\n",
      "\n",
      "    at the class level in their ``__init__`` as explicit keyword\n",
      "\n",
      "    arguments (no ``*args`` or ``**kwargs``).\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    @classmethod\n",
      "\n",
      "    def _get_param_names(cls):\n",
      "\n",
      "        \"\"\"Get parameter names for the estimator\"\"\"\n",
      "\n",
      "        # fetch the constructor or the original constructor before\n",
      "\n",
      "        # deprecation wrapping if any\n",
      "\n",
      "        init = getattr(cls.__init__, \"deprecated_original\", cls.__init__)\n",
      "\n",
      "        if init is object.__init__:\n",
      "\n",
      "            # No explicit constructor to introspect\n",
      "\n",
      "            return []\n",
      "\n",
      "\n",
      "\n",
      "        # introspect the constructor arguments to find the model parameters\n",
      "\n",
      "        # to represent\n",
      "\n",
      "        init_signature = inspect.signature(init)\n",
      "\n",
      "        # Consider the constructor parameters excluding 'self'\n",
      "\n",
      "        parameters = [\n",
      "\n",
      "            p\n",
      "\n",
      "            for p in init_signature.parameters.values()\n",
      "\n",
      "            if p.name != \"self\" and p.kind != p.VAR_KEYWORD\n",
      "\n",
      "        ]\n",
      "\n",
      "        for p in parameters:\n",
      "\n",
      "            if p.kind == p.VAR_POSITIONAL:\n",
      "\n",
      "                raise RuntimeError(\n",
      "\n",
      "                    \"scikit-learn estimators should always \"\n",
      "\n",
      "                    \"specify their parameters in the signature\"\n",
      "\n",
      "                    \" of their __init__ (no varargs).\"\n",
      "\n",
      "                    \" %s with constructor %s doesn't \"\n",
      "\n",
      "                    \" follow this convention.\" % (cls, init_signature)\n",
      "\n",
      "                )\n",
      "\n",
      "        # Extract and sort argument names excluding 'self'\n",
      "\n",
      "        return sorted([p.name for p in parameters])\n",
      "\n",
      "\n",
      "\n",
      "    def get_params(self, deep=True):\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        Get parameters for this estimator.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        deep : bool, default=True\n",
      "\n",
      "            If True, will return the parameters for this estimator and\n",
      "\n",
      "            contained subobjects that are estimators.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        params : dict\n",
      "\n",
      "            Parameter names mapped to their values.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        out = dict()\n",
      "\n",
      "        for key in self._get_param_names():\n",
      "\n",
      "            value = getattr(self, key)\n",
      "\n",
      "            if deep and hasattr(value, \"get_params\"):\n",
      "\n",
      "                deep_items = value.get_params().items()\n",
      "\n",
      "                out.update((key + \"__\" + k, val) for k, val in deep_items)\n",
      "\n",
      "            out[key] = value\n",
      "\n",
      "        return out\n",
      "\n",
      "\n",
      "\n",
      "    def set_params(self, **params):\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        Set the parameters of this estimator.\n",
      "\n",
      "\n",
      "\n",
      "        The method works on simple estimators as well as on nested objects\n",
      "\n",
      "        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "\n",
      "        parameters of the form ``<component>__<parameter>`` so that it's\n",
      "\n",
      "        possible to update each component of a nested object.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        **params : dict\n",
      "\n",
      "            Estimator parameters.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        self : estimator instance\n",
      "\n",
      "            Estimator instance.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        if not params:\n",
      "\n",
      "            # Simple optimization to gain speed (inspect is slow)\n",
      "\n",
      "            return self\n",
      "\n",
      "        valid_params = self.get_params(deep=True)\n",
      "\n",
      "\n",
      "\n",
      "        nested_params = defaultdict(dict)  # grouped by prefix\n",
      "\n",
      "        for key, value in params.items():\n",
      "\n",
      "            key, delim, sub_key = key.partition(\"__\")\n",
      "\n",
      "            if key not in valid_params:\n",
      "\n",
      "                raise ValueError(\n",
      "\n",
      "                    \"Invalid parameter %s for estimator %s. \"\n",
      "\n",
      "                    \"Check the list of available parameters \"\n",
      "\n",
      "                    \"with `estimator.get_params().keys()`.\" % (key, self)\n",
      "\n",
      "                )\n",
      "\n",
      "\n",
      "\n",
      "            if delim:\n",
      "\n",
      "                nested_params[key][sub_key] = value\n",
      "\n",
      "            else:\n",
      "\n",
      "                setattr(self, key, value)\n",
      "\n",
      "                valid_params[key] = value\n",
      "\n",
      "\n",
      "\n",
      "        for key, sub_params in nested_params.items():\n",
      "\n",
      "            valid_params[key].set_params(**sub_params)\n",
      "\n",
      "\n",
      "\n",
      "        return self\n",
      "\n",
      "\n",
      "\n",
      "    def __repr__(self, N_CHAR_MAX=700):\n",
      "\n",
      "        # N_CHAR_MAX is the (approximate) maximum number of non-blank\n",
      "\n",
      "        # characters to render. We pass it as an optional parameter to ease\n",
      "\n",
      "        # the tests.\n",
      "\n",
      "\n",
      "\n",
      "        from .utils._pprint import _EstimatorPrettyPrinter\n",
      "\n",
      "\n",
      "\n",
      "        N_MAX_ELEMENTS_TO_SHOW = 30  # number of elements to show in sequences\n",
      "\n",
      "\n",
      "\n",
      "        # use ellipsis for sequences with a lot of elements\n",
      "\n",
      "        pp = _EstimatorPrettyPrinter(\n",
      "\n",
      "            compact=True,\n",
      "\n",
      "            indent=1,\n",
      "\n",
      "            indent_at_name=True,\n",
      "\n",
      "            n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW,\n",
      "\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "        repr_ = pp.pformat(self)\n",
      "\n",
      "\n",
      "\n",
      "        # Use bruteforce ellipsis when there are a lot of non-blank characters\n",
      "\n",
      "        n_nonblank = len(\"\".join(repr_.split()))\n",
      "\n",
      "        if n_nonblank > N_CHAR_MAX:\n",
      "\n",
      "            lim = N_CHAR_MAX // 2  # apprx number of chars to keep on both ends\n",
      "\n",
      "            regex = r\"^(\\s*\\S){%d}\" % lim\n",
      "\n",
      "            # The regex '^(\\s*\\S){%d}' % n\n",
      "\n",
      "            # matches from the start of the string until the nth non-blank\n",
      "\n",
      "            # character:\n",
      "\n",
      "            # - ^ matches the start of string\n",
      "\n",
      "            # - (pattern){n} matches n repetitions of pattern\n",
      "\n",
      "            # - \\s*\\S matches a non-blank char following zero or more blanks\n",
      "\n",
      "            left_lim = re.match(regex, repr_).end()\n",
      "\n",
      "            right_lim = re.match(regex, repr_[::-1]).end()\n",
      "\n",
      "\n",
      "\n",
      "            if \"\\n\" in repr_[left_lim:-right_lim]:\n",
      "\n",
      "                # The left side and right side aren't on the same line.\n",
      "\n",
      "                # To avoid weird cuts, e.g.:\n",
      "\n",
      "                # categoric...ore',\n",
      "\n",
      "                # we need to start the right side with an appropriate newline\n",
      "\n",
      "                # character so that it renders properly as:\n",
      "\n",
      "                # categoric...\n",
      "\n",
      "                # handle_unknown='ignore',\n",
      "\n",
      "                # so we add [^\\n]*\\n which matches until the next \\n\n",
      "\n",
      "                regex += r\"[^\\n]*\\n\"\n",
      "\n",
      "                right_lim = re.match(regex, repr_[::-1]).end()\n",
      "\n",
      "\n",
      "\n",
      "            ellipsis = \"...\"\n",
      "\n",
      "            if left_lim + len(ellipsis) < len(repr_) - right_lim:\n",
      "\n",
      "                # Only add ellipsis if it results in a shorter repr\n",
      "\n",
      "                repr_ = repr_[:left_lim] + \"...\" + repr_[-right_lim:]\n",
      "\n",
      "\n",
      "\n",
      "        return repr_\n",
      "\n",
      "\n",
      "\n",
      "    def __getstate__(self):\n",
      "\n",
      "        try:\n",
      "\n",
      "            state = super().__getstate__()\n",
      "\n",
      "        except AttributeError:\n",
      "\n",
      "            state = self.__dict__.copy()\n",
      "\n",
      "\n",
      "\n",
      "        if type(self).__module__.startswith(\"sklearn.\"):\n",
      "\n",
      "            return dict(state.items(), _sklearn_version=__version__)\n",
      "\n",
      "        else:\n",
      "\n",
      "            return state\n",
      "\n",
      "\n",
      "\n",
      "    def __setstate__(self, state):\n",
      "\n",
      "        if type(self).__module__.startswith(\"sklearn.\"):\n",
      "\n",
      "            pickle_version = state.pop(\"_sklearn_version\", \"pre-0.18\")\n",
      "\n",
      "            if pickle_version != __version__:\n",
      "\n",
      "                warnings.warn(\n",
      "\n",
      "                    \"Trying to unpickle estimator {0} from version {1} when \"\n",
      "\n",
      "                    \"using version {2}. This might lead to breaking code or \"\n",
      "\n",
      "                    \"invalid results. Use at your own risk. \"\n",
      "\n",
      "                    \"For more info please refer to:\\n\"\n",
      "\n",
      "                    \"https://scikit-learn.org/stable/modules/model_persistence\"\n",
      "\n",
      "                    \".html#security-maintainability-limitations\".format(\n",
      "\n",
      "                        self.__class__.__name__, pickle_version, __version__\n",
      "\n",
      "                    ),\n",
      "\n",
      "                    UserWarning,\n",
      "\n",
      "                )\n",
      "\n",
      "        try:\n",
      "\n",
      "            super().__setstate__(state)\n",
      "\n",
      "        except AttributeError:\n",
      "\n",
      "            self.__dict__.update(state)\n",
      "\n",
      "\n",
      "\n",
      "    def _more_tags(self):\n",
      "\n",
      "        return _DEFAULT_TAGS\n",
      "\n",
      "\n",
      "\n",
      "    def _get_tags(self):\n",
      "\n",
      "        collected_tags = {}\n",
      "\n",
      "        for base_class in reversed(inspect.getmro(self.__class__)):\n",
      "\n",
      "            if hasattr(base_class, \"_more_tags\"):\n",
      "\n",
      "                # need the if because mixins might not have _more_tags\n",
      "\n",
      "                # but might do redundant work in estimators\n",
      "\n",
      "                # (i.e. calling more tags on BaseEstimator multiple times)\n",
      "\n",
      "                more_tags = base_class._more_tags(self)\n",
      "\n",
      "                collected_tags.update(more_tags)\n",
      "\n",
      "        return collected_tags\n",
      "\n",
      "\n",
      "\n",
      "    def _check_n_features(self, X, reset):\n",
      "\n",
      "        \"\"\"Set the `n_features_in_` attribute, or check against it.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "\n",
      "            The input samples.\n",
      "\n",
      "        reset : bool\n",
      "\n",
      "            If True, the `n_features_in_` attribute is set to `X.shape[1]`.\n",
      "\n",
      "            If False and the attribute exists, then check that it is equal to\n",
      "\n",
      "            `X.shape[1]`. If False and the attribute does *not* exist, then\n",
      "\n",
      "            the check is skipped.\n",
      "\n",
      "            .. note::\n",
      "\n",
      "               It is recommended to call reset=True in `fit` and in the first\n",
      "\n",
      "               call to `partial_fit`. All other methods that validate `X`\n",
      "\n",
      "               should set `reset=False`.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        try:\n",
      "\n",
      "            n_features = _num_features(X)\n",
      "\n",
      "        except TypeError as e:\n",
      "\n",
      "            if not reset and hasattr(self, \"n_features_in_\"):\n",
      "\n",
      "                raise ValueError(\n",
      "\n",
      "                    \"X does not contain any features, but \"\n",
      "\n",
      "                    f\"{self.__class__.__name__} is expecting \"\n",
      "\n",
      "                    f\"{self.n_features_in_} features\"\n",
      "\n",
      "                ) from e\n",
      "\n",
      "            # If the number of features is not defined and reset=True,\n",
      "\n",
      "            # then we skip this check\n",
      "\n",
      "            return\n",
      "\n",
      "\n",
      "\n",
      "        if reset:\n",
      "\n",
      "            self.n_features_in_ = n_features\n",
      "\n",
      "            return\n",
      "\n",
      "\n",
      "\n",
      "        if not hasattr(self, \"n_features_in_\"):\n",
      "\n",
      "            # Skip this check if the expected number of expected input features\n",
      "\n",
      "            # was not recorded by calling fit first. This is typically the case\n",
      "\n",
      "            # for stateless transformers.\n",
      "\n",
      "            return\n",
      "\n",
      "\n",
      "\n",
      "        if n_features != self.n_features_in_:\n",
      "\n",
      "            raise ValueError(\n",
      "\n",
      "                f\"X has {n_features} features, but {self.__class__.__name__} \"\n",
      "\n",
      "                f\"is expecting {self.n_features_in_} features as input.\"\n",
      "\n",
      "            )\n",
      "\n",
      "\n",
      "\n",
      "    def _check_feature_names(self, X, *, reset):\n",
      "\n",
      "        \"\"\"Set or check the `feature_names_in_` attribute.\n",
      "\n",
      "\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : {ndarray, dataframe} of shape (n_samples, n_features)\n",
      "\n",
      "            The input samples.\n",
      "\n",
      "\n",
      "\n",
      "        reset : bool\n",
      "\n",
      "            Whether to reset the `feature_names_in_` attribute.\n",
      "\n",
      "            If False, the input will be checked for consistency with\n",
      "\n",
      "            feature names of data provided when reset was last True.\n",
      "\n",
      "            .. note::\n",
      "\n",
      "               It is recommended to call `reset=True` in `fit` and in the first\n",
      "\n",
      "               call to `partial_fit`. All other methods that validate `X`\n",
      "\n",
      "               should set `reset=False`.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "\n",
      "\n",
      "        if reset:\n",
      "\n",
      "            feature_names_in = _get_feature_names(X)\n",
      "\n",
      "            if feature_names_in is not None:\n",
      "\n",
      "                self.feature_names_in_ = feature_names_in\n",
      "\n",
      "            elif hasattr(self, \"feature_names_in_\"):\n",
      "\n",
      "                # Delete the attribute when the estimator is fitted on a new dataset\n",
      "\n",
      "                # that has no feature names.\n",
      "\n",
      "                delattr(self, \"feature_names_in_\")\n",
      "\n",
      "            return\n",
      "\n",
      "\n",
      "\n",
      "        fitted_feature_names = getattr(self, \"feature_names_in_\", None)\n",
      "\n",
      "        X_feature_names = _get_feature_names(X)\n",
      "\n",
      "\n",
      "\n",
      "        if fitted_feature_names is None and X_feature_names is None:\n",
      "\n",
      "            # no feature names seen in fit and in X\n",
      "\n",
      "            return\n",
      "\n",
      "\n",
      "\n",
      "        if X_feature_names is not None and fitted_feature_names is None:\n",
      "\n",
      "            warnings.warn(\n",
      "\n",
      "                f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "\n",
      "                \" feature names\"\n",
      "\n",
      "            )\n",
      "\n",
      "            return\n",
      "\n",
      "\n",
      "\n",
      "        if X_feature_names is None and fitted_feature_names is not None:\n",
      "\n",
      "            warnings.warn(\n",
      "\n",
      "                \"X does not have valid feature names, but\"\n",
      "\n",
      "                f\" {self.__class__.__name__} was fitted with feature names\"\n",
      "\n",
      "            )\n",
      "\n",
      "            return\n",
      "\n",
      "\n",
      "\n",
      "        # validate the feature names against the `feature_names_in_` attribute\n",
      "\n",
      "        if len(fitted_feature_names) != len(X_feature_names) or np.any(\n",
      "\n",
      "            fitted_feature_names != X_feature_names\n",
      "\n",
      "        ):\n",
      "\n",
      "            message = (\n",
      "\n",
      "                \"The feature names should match those that were \"\n",
      "\n",
      "                \"passed during fit. Starting version 1.2, an error will be raised.\\n\"\n",
      "\n",
      "            )\n",
      "\n",
      "            fitted_feature_names_set = set(fitted_feature_names)\n",
      "\n",
      "            X_feature_names_set = set(X_feature_names)\n",
      "\n",
      "\n",
      "\n",
      "            unexpected_names = sorted(X_feature_names_set - fitted_feature_names_set)\n",
      "\n",
      "            missing_names = sorted(fitted_feature_names_set - X_feature_names_set)\n",
      "\n",
      "\n",
      "\n",
      "            def add_names(names):\n",
      "\n",
      "                output = \"\"\n",
      "\n",
      "                max_n_names = 5\n",
      "\n",
      "                for i, name in enumerate(names):\n",
      "\n",
      "                    if i >= max_n_names:\n",
      "\n",
      "                        output += \"- ...\\n\"\n",
      "\n",
      "                        break\n",
      "\n",
      "                    output += f\"- {name}\\n\"\n",
      "\n",
      "                return output\n",
      "\n",
      "\n",
      "\n",
      "            if unexpected_names:\n",
      "\n",
      "                message += \"Feature names unseen at fit time:\\n\"\n",
      "\n",
      "                message += add_names(unexpected_names)\n",
      "\n",
      "\n",
      "\n",
      "            if missing_names:\n",
      "\n",
      "                message += \"Feature names seen at fit time, yet now missing:\\n\"\n",
      "\n",
      "                message += add_names(missing_names)\n",
      "\n",
      "\n",
      "\n",
      "            if not missing_names and not missing_names:\n",
      "\n",
      "                message += (\n",
      "\n",
      "                    \"Feature names must be in the same order as they were in fit.\\n\"\n",
      "\n",
      "                )\n",
      "\n",
      "\n",
      "\n",
      "            warnings.warn(message, FutureWarning)\n",
      "\n",
      "\n",
      "\n",
      "    def _validate_data(\n",
      "\n",
      "        self,\n",
      "\n",
      "        X=\"no_validation\",\n",
      "\n",
      "        y=\"no_validation\",\n",
      "\n",
      "        reset=True,\n",
      "\n",
      "        validate_separately=False,\n",
      "\n",
      "        **check_params,\n",
      "\n",
      "    ):\n",
      "\n",
      "        \"\"\"Validate input data and set or check the `n_features_in_` attribute.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : {array-like, sparse matrix, dataframe} of shape \\\n",
      "\n",
      "                (n_samples, n_features), default='no validation'\n",
      "\n",
      "            The input samples.\n",
      "\n",
      "            If `'no_validation'`, no validation is performed on `X`. This is\n",
      "\n",
      "            useful for meta-estimator which can delegate input validation to\n",
      "\n",
      "            their underlying estimator(s). In that case `y` must be passed and\n",
      "\n",
      "            the only accepted `check_params` are `multi_output` and\n",
      "\n",
      "            `y_numeric`.\n",
      "\n",
      "\n",
      "\n",
      "        y : array-like of shape (n_samples,), default='no_validation'\n",
      "\n",
      "            The targets.\n",
      "\n",
      "\n",
      "\n",
      "            - If `None`, `check_array` is called on `X`. If the estimator's\n",
      "\n",
      "              requires_y tag is True, then an error will be raised.\n",
      "\n",
      "            - If `'no_validation'`, `check_array` is called on `X` and the\n",
      "\n",
      "              estimator's requires_y tag is ignored. This is a default\n",
      "\n",
      "              placeholder and is never meant to be explicitly set. In that case\n",
      "\n",
      "              `X` must be passed.\n",
      "\n",
      "            - Otherwise, only `y` with `_check_y` or both `X` and `y` are\n",
      "\n",
      "              checked with either `check_array` or `check_X_y` depending on\n",
      "\n",
      "              `validate_separately`.\n",
      "\n",
      "\n",
      "\n",
      "        reset : bool, default=True\n",
      "\n",
      "            Whether to reset the `n_features_in_` attribute.\n",
      "\n",
      "            If False, the input will be checked for consistency with data\n",
      "\n",
      "            provided when reset was last True.\n",
      "\n",
      "            .. note::\n",
      "\n",
      "               It is recommended to call reset=True in `fit` and in the first\n",
      "\n",
      "               call to `partial_fit`. All other methods that validate `X`\n",
      "\n",
      "               should set `reset=False`.\n",
      "\n",
      "        validate_separately : False or tuple of dicts, default=False\n",
      "\n",
      "            Only used if y is not None.\n",
      "\n",
      "            If False, call validate_X_y(). Else, it must be a tuple of kwargs\n",
      "\n",
      "            to be used for calling check_array() on X and y respectively.\n",
      "\n",
      "        **check_params : kwargs\n",
      "\n",
      "            Parameters passed to :func:`sklearn.utils.check_array` or\n",
      "\n",
      "            :func:`sklearn.utils.check_X_y`. Ignored if validate_separately\n",
      "\n",
      "            is not False.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        out : {ndarray, sparse matrix} or tuple of these\n",
      "\n",
      "            The validated input. A tuple is returned if both `X` and `y` are\n",
      "\n",
      "            validated.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        self._check_feature_names(X, reset=reset)\n",
      "\n",
      "\n",
      "\n",
      "        if y is None and self._get_tags()[\"requires_y\"]:\n",
      "\n",
      "            raise ValueError(\n",
      "\n",
      "                f\"This {self.__class__.__name__} estimator \"\n",
      "\n",
      "                \"requires y to be passed, but the target y is None.\"\n",
      "\n",
      "            )\n",
      "\n",
      "\n",
      "\n",
      "        no_val_X = isinstance(X, str) and X == \"no_validation\"\n",
      "\n",
      "        no_val_y = y is None or isinstance(y, str) and y == \"no_validation\"\n",
      "\n",
      "\n",
      "\n",
      "        if no_val_X and no_val_y:\n",
      "\n",
      "            raise ValueError(\"Validation should be done on X, y or both.\")\n",
      "\n",
      "        elif not no_val_X and no_val_y:\n",
      "\n",
      "            X = check_array(X, **check_params)\n",
      "\n",
      "            out = X\n",
      "\n",
      "        elif no_val_X and not no_val_y:\n",
      "\n",
      "            y = _check_y(y, **check_params)\n",
      "\n",
      "            out = y\n",
      "\n",
      "        else:\n",
      "\n",
      "            if validate_separately:\n",
      "\n",
      "                # We need this because some estimators validate X and y\n",
      "\n",
      "                # separately, and in general, separately calling check_array()\n",
      "\n",
      "                # on X and y isn't equivalent to just calling check_X_y()\n",
      "\n",
      "                # :(\n",
      "\n",
      "                check_X_params, check_y_params = validate_separately\n",
      "\n",
      "                X = check_array(X, **check_X_params)\n",
      "\n",
      "                y = check_array(y, **check_y_params)\n",
      "\n",
      "            else:\n",
      "\n",
      "                X, y = check_X_y(X, y, **check_params)\n",
      "\n",
      "            out = X, y\n",
      "\n",
      "\n",
      "\n",
      "        if not no_val_X and check_params.get(\"ensure_2d\", True):\n",
      "\n",
      "            self._check_n_features(X, reset=reset)\n",
      "\n",
      "\n",
      "\n",
      "        return out\n",
      "\n",
      "\n",
      "\n",
      "    @property\n",
      "\n",
      "    def _repr_html_(self):\n",
      "\n",
      "        \"\"\"HTML representation of estimator.\n",
      "\n",
      "\n",
      "\n",
      "        This is redundant with the logic of `_repr_mimebundle_`. The latter\n",
      "\n",
      "        should be favorted in the long term, `_repr_html_` is only\n",
      "\n",
      "        implemented for consumers who do not interpret `_repr_mimbundle_`.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        if get_config()[\"display\"] != \"diagram\":\n",
      "\n",
      "            raise AttributeError(\n",
      "\n",
      "                \"_repr_html_ is only defined when the \"\n",
      "\n",
      "                \"'display' configuration option is set to \"\n",
      "\n",
      "                \"'diagram'\"\n",
      "\n",
      "            )\n",
      "\n",
      "        return self._repr_html_inner\n",
      "\n",
      "\n",
      "\n",
      "    def _repr_html_inner(self):\n",
      "\n",
      "        \"\"\"This function is returned by the @property `_repr_html_` to make\n",
      "\n",
      "        `hasattr(estimator, \"_repr_html_\") return `True` or `False` depending\n",
      "\n",
      "        on `get_config()[\"display\"]`.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        return estimator_html_repr(self)\n",
      "\n",
      "\n",
      "\n",
      "    def _repr_mimebundle_(self, **kwargs):\n",
      "\n",
      "        \"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\n",
      "\n",
      "        output = {\"text/plain\": repr(self)}\n",
      "\n",
      "        if get_config()[\"display\"] == \"diagram\":\n",
      "\n",
      "            output[\"text/html\"] = estimator_html_repr(self)\n",
      "\n",
      "        return output\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class ClassifierMixin:\n",
      "\n",
      "    \"\"\"Mixin class for all classifiers in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    _estimator_type = \"classifier\"\n",
      "\n",
      "\n",
      "\n",
      "    def score(self, X, y, sample_weight=None):\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        Return the mean accuracy on the given test data and labels.\n",
      "\n",
      "\n",
      "\n",
      "        In multi-label classification, this is the subset accuracy\n",
      "\n",
      "        which is a harsh metric since you require for each sample that\n",
      "\n",
      "        each label set be correctly predicted.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "\n",
      "            Test samples.\n",
      "\n",
      "\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "\n",
      "            True labels for `X`.\n",
      "\n",
      "\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "\n",
      "            Sample weights.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        score : float\n",
      "\n",
      "            Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        from .metrics import accuracy_score\n",
      "\n",
      "\n",
      "\n",
      "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "\n",
      "\n",
      "\n",
      "    def _more_tags(self):\n",
      "\n",
      "        return {\"requires_y\": True}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class RegressorMixin:\n",
      "\n",
      "    \"\"\"Mixin class for all regression estimators in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    _estimator_type = \"regressor\"\n",
      "\n",
      "\n",
      "\n",
      "    def score(self, X, y, sample_weight=None):\n",
      "\n",
      "        \"\"\"Return the coefficient of determination of the prediction.\n",
      "\n",
      "\n",
      "\n",
      "        The coefficient of determination :math:`R^2` is defined as\n",
      "\n",
      "        :math:`(1 - \\\\frac{u}{v})`, where :math:`u` is the residual\n",
      "\n",
      "        sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "\n",
      "        is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "\n",
      "        The best possible score is 1.0 and it can be negative (because the\n",
      "\n",
      "        model can be arbitrarily worse). A constant model that always predicts\n",
      "\n",
      "        the expected value of `y`, disregarding the input features, would get\n",
      "\n",
      "        a :math:`R^2` score of 0.0.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "\n",
      "            Test samples. For some estimators this may be a precomputed\n",
      "\n",
      "            kernel matrix or a list of generic objects instead with shape\n",
      "\n",
      "            ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "\n",
      "            is the number of samples used in the fitting for the estimator.\n",
      "\n",
      "\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "\n",
      "            True values for `X`.\n",
      "\n",
      "\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "\n",
      "            Sample weights.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        score : float\n",
      "\n",
      "            :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      "\n",
      "\n",
      "\n",
      "        Notes\n",
      "\n",
      "        -----\n",
      "\n",
      "        The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "\n",
      "        ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "\n",
      "        with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "\n",
      "        This influences the ``score`` method of all the multioutput\n",
      "\n",
      "        regressors (except for\n",
      "\n",
      "        :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "\n",
      "\n",
      "        from .metrics import r2_score\n",
      "\n",
      "\n",
      "\n",
      "        y_pred = self.predict(X)\n",
      "\n",
      "        return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "\n",
      "\n",
      "\n",
      "    def _more_tags(self):\n",
      "\n",
      "        return {\"requires_y\": True}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class ClusterMixin:\n",
      "\n",
      "    \"\"\"Mixin class for all cluster estimators in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    _estimator_type = \"clusterer\"\n",
      "\n",
      "\n",
      "\n",
      "    def fit_predict(self, X, y=None):\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        Perform clustering on `X` and returns cluster labels.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "\n",
      "            Input data.\n",
      "\n",
      "\n",
      "\n",
      "        y : Ignored\n",
      "\n",
      "            Not used, present for API consistency by convention.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        labels : ndarray of shape (n_samples,), dtype=np.int64\n",
      "\n",
      "            Cluster labels.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        # non-optimized default implementation; override when a better\n",
      "\n",
      "        # method is possible for a given clustering algorithm\n",
      "\n",
      "        self.fit(X)\n",
      "\n",
      "        return self.labels_\n",
      "\n",
      "\n",
      "\n",
      "    def _more_tags(self):\n",
      "\n",
      "        return {\"preserves_dtype\": []}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class BiclusterMixin:\n",
      "\n",
      "    \"\"\"Mixin class for all bicluster estimators in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    @property\n",
      "\n",
      "    def biclusters_(self):\n",
      "\n",
      "        \"\"\"Convenient way to get row and column indicators together.\n",
      "\n",
      "\n",
      "\n",
      "        Returns the ``rows_`` and ``columns_`` members.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        return self.rows_, self.columns_\n",
      "\n",
      "\n",
      "\n",
      "    def get_indices(self, i):\n",
      "\n",
      "        \"\"\"Row and column indices of the `i`'th bicluster.\n",
      "\n",
      "\n",
      "\n",
      "        Only works if ``rows_`` and ``columns_`` attributes exist.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        i : int\n",
      "\n",
      "            The index of the cluster.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        row_ind : ndarray, dtype=np.intp\n",
      "\n",
      "            Indices of rows in the dataset that belong to the bicluster.\n",
      "\n",
      "        col_ind : ndarray, dtype=np.intp\n",
      "\n",
      "            Indices of columns in the dataset that belong to the bicluster.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        rows = self.rows_[i]\n",
      "\n",
      "        columns = self.columns_[i]\n",
      "\n",
      "        return np.nonzero(rows)[0], np.nonzero(columns)[0]\n",
      "\n",
      "\n",
      "\n",
      "    def get_shape(self, i):\n",
      "\n",
      "        \"\"\"Shape of the `i`'th bicluster.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        i : int\n",
      "\n",
      "            The index of the cluster.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        n_rows : int\n",
      "\n",
      "            Number of rows in the bicluster.\n",
      "\n",
      "\n",
      "\n",
      "        n_cols : int\n",
      "\n",
      "            Number of columns in the bicluster.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        indices = self.get_indices(i)\n",
      "\n",
      "        return tuple(len(i) for i in indices)\n",
      "\n",
      "\n",
      "\n",
      "    def get_submatrix(self, i, data):\n",
      "\n",
      "        \"\"\"Return the submatrix corresponding to bicluster `i`.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        i : int\n",
      "\n",
      "            The index of the cluster.\n",
      "\n",
      "        data : array-like of shape (n_samples, n_features)\n",
      "\n",
      "            The data.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        submatrix : ndarray of shape (n_rows, n_cols)\n",
      "\n",
      "            The submatrix corresponding to bicluster `i`.\n",
      "\n",
      "\n",
      "\n",
      "        Notes\n",
      "\n",
      "        -----\n",
      "\n",
      "        Works with sparse matrices. Only works if ``rows_`` and\n",
      "\n",
      "        ``columns_`` attributes exist.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        from .utils.validation import check_array\n",
      "\n",
      "\n",
      "\n",
      "        data = check_array(data, accept_sparse=\"csr\")\n",
      "\n",
      "        row_ind, col_ind = self.get_indices(i)\n",
      "\n",
      "        return data[row_ind[:, np.newaxis], col_ind]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class TransformerMixin:\n",
      "\n",
      "    \"\"\"Mixin class for all transformers in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    def fit_transform(self, X, y=None, **fit_params):\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        Fit to data, then transform it.\n",
      "\n",
      "\n",
      "\n",
      "        Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "\n",
      "        and returns a transformed version of `X`.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "\n",
      "            Input samples.\n",
      "\n",
      "\n",
      "\n",
      "        y :  array-like of shape (n_samples,) or (n_samples, n_outputs), \\\n",
      "\n",
      "                default=None\n",
      "\n",
      "            Target values (None for unsupervised transformations).\n",
      "\n",
      "\n",
      "\n",
      "        **fit_params : dict\n",
      "\n",
      "            Additional fit parameters.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "\n",
      "            Transformed array.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        # non-optimized default implementation; override when a better\n",
      "\n",
      "        # method is possible for a given clustering algorithm\n",
      "\n",
      "        if y is None:\n",
      "\n",
      "            # fit method of arity 1 (unsupervised transformation)\n",
      "\n",
      "            return self.fit(X, **fit_params).transform(X)\n",
      "\n",
      "        else:\n",
      "\n",
      "            # fit method of arity 2 (supervised transformation)\n",
      "\n",
      "            return self.fit(X, y, **fit_params).transform(X)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class _OneToOneFeatureMixin:\n",
      "\n",
      "    \"\"\"Provides `get_feature_names_out` for simple transformers.\n",
      "\n",
      "\n",
      "\n",
      "    Assumes there's a 1-to-1 correspondence between input features\n",
      "\n",
      "    and output features.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    def get_feature_names_out(self, input_features=None):\n",
      "\n",
      "        \"\"\"Get output feature names for transformation.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        input_features : array-like of str or None, default=None\n",
      "\n",
      "            Input features.\n",
      "\n",
      "\n",
      "\n",
      "            - If `input_features` is `None`, then `feature_names_in_` is\n",
      "\n",
      "              used as feature names in. If `feature_names_in_` is not defined,\n",
      "\n",
      "              then names are generated: `[x0, x1, ..., x(n_features_in_)]`.\n",
      "\n",
      "            - If `input_features` is an array-like, then `input_features` must\n",
      "\n",
      "              match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        feature_names_out : ndarray of str objects\n",
      "\n",
      "            Same as input features.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        return _check_feature_names_in(self, input_features)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class DensityMixin:\n",
      "\n",
      "    \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    _estimator_type = \"DensityEstimator\"\n",
      "\n",
      "\n",
      "\n",
      "    def score(self, X, y=None):\n",
      "\n",
      "        \"\"\"Return the score of the model on the data `X`.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "\n",
      "            Test samples.\n",
      "\n",
      "\n",
      "\n",
      "        y : Ignored\n",
      "\n",
      "            Not used, present for API consistency by convention.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        score : float\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class OutlierMixin:\n",
      "\n",
      "    \"\"\"Mixin class for all outlier detection estimators in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    _estimator_type = \"outlier_detector\"\n",
      "\n",
      "\n",
      "\n",
      "    def fit_predict(self, X, y=None):\n",
      "\n",
      "        \"\"\"Perform fit on X and returns labels for X.\n",
      "\n",
      "\n",
      "\n",
      "        Returns -1 for outliers and 1 for inliers.\n",
      "\n",
      "\n",
      "\n",
      "        Parameters\n",
      "\n",
      "        ----------\n",
      "\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "\n",
      "            The input samples.\n",
      "\n",
      "\n",
      "\n",
      "        y : Ignored\n",
      "\n",
      "            Not used, present for API consistency by convention.\n",
      "\n",
      "\n",
      "\n",
      "        Returns\n",
      "\n",
      "        -------\n",
      "\n",
      "        y : ndarray of shape (n_samples,)\n",
      "\n",
      "            1 for inliers, -1 for outliers.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        # override for transductive outlier detectors like LocalOulierFactor\n",
      "\n",
      "        return self.fit(X).predict(X)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class MetaEstimatorMixin:\n",
      "\n",
      "    _required_parameters = [\"estimator\"]\n",
      "\n",
      "    \"\"\"Mixin class for all meta estimators in scikit-learn.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class MultiOutputMixin:\n",
      "\n",
      "    \"\"\"Mixin to mark estimators that support multioutput.\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    def _more_tags(self):\n",
      "\n",
      "        return {\"multioutput\": True}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class _UnstableArchMixin:\n",
      "\n",
      "    \"\"\"Mark estimators that are non-determinstic on 32bit or PowerPC\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "    def _more_tags(self):\n",
      "\n",
      "        return {\n",
      "\n",
      "            \"non_deterministic\": (\n",
      "\n",
      "                _IS_32BIT or platform.machine().startswith((\"ppc\", \"powerpc\"))\n",
      "\n",
      "            )\n",
      "\n",
      "        }\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def is_classifier(estimator):\n",
      "\n",
      "    \"\"\"Return True if the given estimator is (probably) a classifier.\n",
      "\n",
      "\n",
      "\n",
      "    Parameters\n",
      "\n",
      "    ----------\n",
      "\n",
      "    estimator : object\n",
      "\n",
      "        Estimator object to test.\n",
      "\n",
      "\n",
      "\n",
      "    Returns\n",
      "\n",
      "    -------\n",
      "\n",
      "    out : bool\n",
      "\n",
      "        True if estimator is a classifier and False otherwise.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    return getattr(estimator, \"_estimator_type\", None) == \"classifier\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def is_regressor(estimator):\n",
      "\n",
      "    \"\"\"Return True if the given estimator is (probably) a regressor.\n",
      "\n",
      "\n",
      "\n",
      "    Parameters\n",
      "\n",
      "    ----------\n",
      "\n",
      "    estimator : estimator instance\n",
      "\n",
      "        Estimator object to test.\n",
      "\n",
      "\n",
      "\n",
      "    Returns\n",
      "\n",
      "    -------\n",
      "\n",
      "    out : bool\n",
      "\n",
      "        True if estimator is a regressor and False otherwise.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    return getattr(estimator, \"_estimator_type\", None) == \"regressor\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def is_outlier_detector(estimator):\n",
      "\n",
      "    \"\"\"Return True if the given estimator is (probably) an outlier detector.\n",
      "\n",
      "\n",
      "\n",
      "    Parameters\n",
      "\n",
      "    ----------\n",
      "\n",
      "    estimator : estimator instance\n",
      "\n",
      "        Estimator object to test.\n",
      "\n",
      "\n",
      "\n",
      "    Returns\n",
      "\n",
      "    -------\n",
      "\n",
      "    out : bool\n",
      "\n",
      "        True if estimator is an outlier detector and False otherwise.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    return getattr(estimator, \"_estimator_type\", None) == \"outlier_detector\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def _is_pairwise(estimator):\n",
      "\n",
      "    \"\"\"Returns True if estimator is pairwise.\n",
      "\n",
      "\n",
      "\n",
      "    - If the `_pairwise` attribute and the tag are present and consistent,\n",
      "\n",
      "      then use the value and not issue a warning.\n",
      "\n",
      "    - If the `_pairwise` attribute and the tag are present and not\n",
      "\n",
      "      consistent, use the `_pairwise` value and issue a deprecation\n",
      "\n",
      "      warning.\n",
      "\n",
      "    - If only the `_pairwise` attribute is present and it is not False,\n",
      "\n",
      "      issue a deprecation warning and use the `_pairwise` value.\n",
      "\n",
      "\n",
      "\n",
      "    Parameters\n",
      "\n",
      "    ----------\n",
      "\n",
      "    estimator : object\n",
      "\n",
      "        Estimator object to test.\n",
      "\n",
      "\n",
      "\n",
      "    Returns\n",
      "\n",
      "    -------\n",
      "\n",
      "    out : bool\n",
      "\n",
      "        True if the estimator is pairwise and False otherwise.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    with warnings.catch_warnings():\n",
      "\n",
      "        warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
      "\n",
      "        has_pairwise_attribute = hasattr(estimator, \"_pairwise\")\n",
      "\n",
      "        pairwise_attribute = getattr(estimator, \"_pairwise\", False)\n",
      "\n",
      "    pairwise_tag = _safe_tags(estimator, key=\"pairwise\")\n",
      "\n",
      "\n",
      "\n",
      "    if has_pairwise_attribute:\n",
      "\n",
      "        if pairwise_attribute != pairwise_tag:\n",
      "\n",
      "            warnings.warn(\n",
      "\n",
      "                \"_pairwise was deprecated in 0.24 and will be removed in 1.1 \"\n",
      "\n",
      "                \"(renaming of 0.26). Set the estimator tags of your estimator \"\n",
      "\n",
      "                \"instead\",\n",
      "\n",
      "                FutureWarning,\n",
      "\n",
      "            )\n",
      "\n",
      "        return pairwise_attribute\n",
      "\n",
      "\n",
      "\n",
      "    # use pairwise tag when the attribute is not present\n",
      "\n",
      "    return pairwise_tag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "# for line in inspect.findsource(LinearRegression)[0]:\n",
    "#     print(line)\n",
    "    \n",
    "for line in inspect.findsource(sklearn.base.MultiOutputMixin)[0]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e780cae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearRegression in module sklearn.linear_model._base:\n",
      "\n",
      "class LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, LinearModel)\n",
      " |  LinearRegression(*, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      " |  to minimize the residual sum of squares between the observed targets in\n",
      " |  the dataset, and the targets predicted by the linear approximation.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be centered).\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |         `normalize` was deprecated in version 1.0 and will be\n",
      " |         removed in 1.2.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup in case of sufficiently large problems, that is if firstly\n",
      " |      `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
      " |      to `True`. ``None`` means 1 unless in a\n",
      " |      :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
      " |      processors. See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive. This\n",
      " |      option is only supported for dense arrays.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  rank_ : int\n",
      " |      Rank of matrix `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  singular_ : array of shape (min(X, y),)\n",
      " |      Singular values of `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  intercept_ : float or array of shape (n_targets,)\n",
      " |      Independent term in the linear model. Set to 0.0 if\n",
      " |      `fit_intercept = False`.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  Ridge : Ridge regression addresses some of the\n",
      " |      problems of Ordinary Least Squares by imposing a penalty on the\n",
      " |      size of the coefficients with l2 regularization.\n",
      " |  Lasso : The Lasso is a linear model that estimates\n",
      " |      sparse coefficients with l1 regularization.\n",
      " |  ElasticNet : Elastic-Net is a linear regression\n",
      " |      model trained with both l1 and l2 -norm regularization of the\n",
      " |      coefficients.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
      " |  (scipy.optimize.nnls) wrapped as a predictor object.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_\n",
      " |  3.0...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted Estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(LinearRegression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d13427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycodestyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06fe4848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pycodestyle' from '/Users/christianschreurs/anaconda3/lib/python3.8/site-packages/pycodestyle.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycodestyle # in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054aec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
